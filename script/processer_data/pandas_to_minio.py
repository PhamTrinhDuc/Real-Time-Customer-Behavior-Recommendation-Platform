import os
import pandas as pd
import psycopg2
import shutil
from pathlib import Path
from deltalake.writer import write_deltalake
from minio_client import MinioClient
import argparse
from dotenv import load_dotenv
load_dotenv()

# Config
LOCAL_DELTA_PATH = "./script/spark/processer_data/delta_data"  # Local Delta Lake path
BUCKET_NAME = "ecommerce"
FOLDER_NAME = "data_postgres"

DB_CONFIG = {
    'host': 'localhost',
    'port': os.getenv('POSTGRES_PORT'),
    'database': os.getenv('POSTGRES_DB'),
    'user': os.getenv('POSTGRES_USER'),
    'password': os.getenv('POSTGRES_PASSWORD')
}

def clean_dataframe_for_delta(df, table_name):
    """Clean DataFrame ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi Delta Lake"""
    print(f"üßπ Cleaning DataFrame for table {table_name}")
    
    df_cleaned = df.copy()
    
    # X·ª≠ l√Ω c√°c columns to√†n NULL
    for col in df_cleaned.columns:
        if df_cleaned[col].isnull().all():
            print(f"‚ö†Ô∏è Column '{col}' is all NULL - converting to string type")
            df_cleaned[col] = df_cleaned[col].astype('object').fillna('')
        elif df_cleaned[col].dtype == 'object':
            # ƒê·∫£m b·∫£o object columns kh√¥ng c√≥ mixed types
            df_cleaned[col] = df_cleaned[col].astype(str).replace('nan', '')
    
    # Convert problematic data types
    for col in df_cleaned.columns:
        dtype = df_cleaned[col].dtype
        
        # Handle datetime columns
        if 'datetime' in str(dtype):
            df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')
            if pd.api.types.is_datetime64tz_dtype(df_cleaned[col]):
                df_cleaned[col] = df_cleaned[col].dt.tz_convert(None)  # b·ªè timezone
                
        # x·ª≠ l√Ω ri√™ng cho updated_at, created_at
        elif col in ['updated_at', 'created_at']:
            df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')
            if pd.api.types.is_datetime64tz_dtype(df_cleaned[col]):
                df_cleaned[col] = df_cleaned[col].dt.tz_convert(None)  # b·ªè timezone
        
        # Handle mixed int/float with nulls
        elif dtype == 'object' and col not in ['created_at', 'updated_at']:
            # Try to convert to numeric if possible
            try:
                numeric_series = pd.to_numeric(df_cleaned[col], errors='coerce')
                if not numeric_series.isnull().all():
                    df_cleaned[col] = numeric_series
            except:
                pass
    
    print(f"Cleaned DataFrame shape: {df_cleaned.shape}")
    return df_cleaned

def upload_delta_table_to_minio(minio_client, local_path, bucket_name, table_name):
    """Upload to√†n b·ªô Delta Lake table (bao g·ªìm _delta_log) l√™n MinIO"""
    local_path = Path(local_path)
    
    if not local_path.exists():
        print(f"Local path {local_path} kh√¥ng t·ªìn t·∫°i")
        return False
        
    # Upload t·∫•t c·∫£ files trong Delta table
    for file_path in local_path.rglob('*'):
        if file_path.is_file():
            # T·∫°o relative path cho MinIO object
            relative_path = file_path.relative_to(local_path)
            object_name = f"{FOLDER_NAME}/{table_name}/{relative_path}"
            
            try:
                minio_client.fput_object(
                    bucket_name=bucket_name,
                    object_name=object_name,
                    file_path=str(file_path)
                )
                print(f"üì§ Uploaded: {object_name}")
            except Exception as e:
                print(f"‚ùå Failed to upload {file_path}: {e}")
                return False
                
    return True

def pandas_to_minio(minio_client, tables: list):
    # T·∫°o local delta directory
    os.makedirs(LOCAL_DELTA_PATH, exist_ok=True)
    
    # K·∫øt n·ªëi MinIO
    minio_client.create_bucket_if_not_exists(bucket_name=BUCKET_NAME)
    
    # K·∫øt n·ªëi PostgreSQL
    conn = psycopg2.connect(**DB_CONFIG)
    
    if not isinstance(tables, list): 
        tables = [tables]

    for table in tables:
        print(f"Processing table: {table}")
        
        try:
            # ƒê·ªçc data b·∫±ng pandas
            df = pd.read_sql(f"SELECT * FROM {table}", conn)
            
            if len(df) == 0:
                print(f"Table {table} is empty, skipping...")
                continue
            
            # Clean DataFrame cho Delta Lake
            df_cleaned = clean_dataframe_for_delta(df, table)
            
            # T·∫°o Delta Lake table local
            table_path = os.path.join(LOCAL_DELTA_PATH, table)
            print(f"Writing Delta Lake table to {table_path}")
            
            # X√≥a table c≈© n·∫øu c√≥
            if os.path.exists(table_path):
                shutil.rmtree(table_path)
            
            # Vi·∫øt Delta Lake table v·ªõi cleaned data
            write_deltalake(
                table_or_uri=table_path,
                data=df_cleaned,
                mode="append",
                overwrite_schema=True
            )
            
            # Upload to√†n b·ªô Delta table l√™n MinIO
            print(f"Uploading {table} to MinIO...")
            success = upload_delta_table_to_minio(
                minio_client=minio_client.client,
                local_path=table_path,
                bucket_name=BUCKET_NAME,
                table_name=table
            )
            
            if success:
                print(f"Successfully uploaded {table} Delta table to MinIO")
            else:
                print(f"Failed to upload {table}")
                
        except Exception as e:
            print(f"Error processing table {table}: {str(e)}")
            continue
    
    conn.close()
    print(f"üéâ All tables processed! Local Delta files: {LOCAL_DELTA_PATH}")

if __name__ == "__main__":
    minio_client = MinioClient()
    
    parser = argparse.ArgumentParser(description="Pandas to minio")
    parser.add_argument("--clear_bucket", type=str, help="Remove bucket on minio")
    parser.add_argument("--tables", type=str, default="orders,order_items,payments,customers,products,categories", help="Push data of tables on minio")
    
    args = parser.parse_args()

    if args.clear_bucket:
        minio_client.delete_bucket_if_not_exists(bucket_name=args.clear_bucket)
    else:
        pandas_to_minio(minio_client=minio_client, tables=args.tables.split(","))

    
    